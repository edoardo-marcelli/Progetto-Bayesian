---
header-includes:
- \usepackage{txfonts}
- \usepackage{amsmath}
- \usepackage[bindingoffset=1.5cm, left=3cm, right=3cm, top=3cm, bottom=3cm]{geometry}
- \usepackage{graphicx}
- \usepackage{MnSymbol} %allows to insert the QED at the end of the proofs
- \usepackage{hyperref} %set the hyperlink to cite sections, equations...
- \urlstyle{same}
- \usepackage{comment}
- \usepackage{enumitem}
- \usepackage{ntheorem}
- \usepackage{lipsum}
- \usepackage{amssymb}
- \usepackage{xcolor}
- \theoremstyle{break}
- \newtheorem{thm}{Theorem}% theorem counter resets every \subsection
- \renewcommand{\thethm}{\arabic{thm}}
- \newtheorem{proposition}{Proposition}
- \newtheorem{assumption}{Assumption}
- \newtheorem{lemma}{Lemma}
- \theoremstyle{nonumberplain}
- \newtheorem{proof*}{Proof.}
- \newtheorem{definition}{Definition}
- \renewcommand{\P}{\mathbb{P}}
- \newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
- \def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
- \setcounter{MaxMatrixCols}{10}
- \setlength{\oddsidemargin}{.0in}
- \setlength{\textwidth}{6 in}
- \setlength{\topmargin}{-.1in}
- \setlength{\textheight}{8.1in}
- \renewcommand{\baselinestretch}{1.5}
- \usepackage{amssymb}
- \newcommand{\E}{\mathbb E}
- \newcommand{\Q}{\mathbb Q}
- \newcommand{\M}{\mathbb M}
- \newcommand{\R}{\mathbb R}
- \newcommand{\B}{\mathcal B}
- \newcommand{\X}{\mathcal X}
- \newcommand{\Pd}{\mathbb P}
- \def\code#1{\texttt{#1}}
- \newtheorem{algorithm}{Algorithm}[section]

title: "Final draft"

documentclass: book

output:
  pdf_document: 
   latex_engine: xelatex
   fig_width: 5
   fig_height: 3.5
   fig_caption: true
   extra_dependencies: ["float"]
   number_sections: true 

---
```{r, results= FALSE, message=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = '')
knitr::opts_chunk$set(out.extra='')
```
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
Sys.setlocale("LC_TIME", "English")
```
```{r include=FALSE}
library(ggplot2)
library(ggpubr)
library(kableExtra)
```
\chapter*{Introduction}

\chapter{Markov Processes and State-Space Models}
\section{Notation}
Let us fix the basic notation that will be employed henceforth. Upper case letters, e.g. $X_t, Y_t,$ denote random variables, while lower case letters 
denote the realizations. Finite sequences are made compact using the semi-colon notation, e.g. $x_{0:t}=(x_0, x_1, \dots, x_t)$ for some $t \geq 0.$ The sets of outcomes are denoted by upper case calligraphic letters, e.g. $\mathcal{X}, \mathcal{Y}.$  The $\sigma$-algebra
of a set $\mathcal{X}$ reads $\mathcal{B}(\mathcal{X}).$ The pair $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$ is a measurable space.
The densities are represented with lower case cursive letters. For example, the density of $X_t$ in $x_t$ is $p_t^\theta(x_t),$ where $\theta\in\Theta$ is some (eventually known) vector, while the density 
of $X_t$ in $x_t,$ given that $X_{t-1}$ has previously taken value $x_{t-1},$ is $p_t^\theta(x_t\mid x_{t-1}).$  Note that $p_t^\theta(x_t\mid x_{t-1})$ is a member of the parametric family with parameters $(\theta, x_{t-1})$.
The probability distribution of a random variable $X_t$ is represented by $\mathbb{P}_t(dx_t),$ while the probability distribution of a sequence $X_{0:t}$ is represented by $\mathbb{P}_t(dx_{0:t}).$ The Dirac measure, i.e., the measure that assigns probability $1$ to the singleton $\{x\},$ is denoted by $\delta_x(dy)$.The expectation operator is denoted by $\mathbb{E},$ where the section of $\mathbb{E}$ at $\mathbb{Q},$ i.e., $\mathbb{E}_{\mathbb{Q}}$ denotes the operator computed with respect to the probability distribution $\mathbb{Q}.$ 
Let $\varphi$ be a function defined on the random variable $X\propto\mathbb{Q}.$ Then, we denote the expected value of $\varphi(X)$ with 
$$
    \mathbb{E}_{\mathbb{Q}}[\varphi(X)]=
    \int_{\mathbb{X}}\varphi(x)\mathbb{Q}(dx).
$$

\section{Markov Processes}
Let $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$ and $(\mathcal{Y}, \mathcal{B}(\mathcal{Y}))$ be two (eventually equal) measurable spaces. 
\begin{definition}
A function $P(x,dy): (\mathcal{X}, \mathcal{B}(\mathcal{X}))\rightarrow [0,1]$ such that 
\begin{itemize}
    \item for all $x\in\mathcal{X}, P(x,\cdot)$ is a probability measure on $(\mathcal{Y}, \mathcal{B}(\mathcal{Y})$, and 
    \item for all subsets $A\in\mathcal{B}(\mathcal{Y}),$ the map $x\mapsto P(x,A)$ is measurable in $\mathcal{B}(\mathcal{X})),$
\end{itemize}
is defined a probability kernel from $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$ to $(\mathcal{Y}, \mathcal{B}(\mathcal{Y})).$
\end{definition}
Notice that for any random variables $X_1$ and $X_0=x_0,$ 
$$
    \mathbb{P}_1(dx_{0:1})=\mathbb{P}_0(dx_{0})P_1(x_0,dx_1),
$$
where $P_1(x_0,dx_1)$ is a probability kernel from $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$ to $(\mathcal{X}, \mathcal{B}(\mathcal{X})).$ This remark, provides some intuition about the link between probability kernels and conditional probabilities. As a matter of fact, it is possible to show that for given $X_{0:1}$ with probability distribution $\mathbb{P}_1(dx_{0:1}),$ 
\begin{equation}\label{prob_kern_condit_prob}
    \mathbb{P}_1(X_1\in dx_1\mid X_0=x_0)=P_1(x_0,dx_1).
\end{equation}

Probability kernels can be used to define Markov processes. Before moving to the definition, we will introduce some important concepts. Recall that given two measures $\mathbb{M}$ and $\mathbb{Q}$ defined on a measurable space $(\mathcal{X}, \mathcal{B}(\mathcal{X})),$ $\mathbb{Q}$ is absolutely continuous with respect to $\mathbb{M},$ that is $\mathbb{Q}\ll\mathbb{M},$ if for all sets $A\in\mathcal{B}(\mathcal{X})$ such that $\mathbb{M}(A)=0,$ then it must also hold that $\mathbb{Q}(A)=0.$ If $\mathbb{Q}(A)/\mathbb{M}(A)$ is well-defined for all $A,$ then the Radon-Nikodym theorem guarantees that there exists a measurable function $w(x)\geq0$ such that 
$$
    w(x)=\frac{\mathbb{Q}(dx)}{\mathbb{M}(dx)}, 
$$
meaning that, 
$$
    \mathbb{Q}(A)=\int_\mathcal{X} w(x) \mathbb{M}(dx).
$$

Let $P_1, P_2, \dots, P_T$ be a finite measure of probability kernels from $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$ to $(\mathcal{X}, \mathcal{B}(\mathcal{X})).$ Fix some $\mathbb{P}_0(dx)$ on $(\mathcal{X}, \mathcal{B}(\mathcal{X})).$ \begin{definition}
A discrete-time Markov process is a sequence $X_{0:T}$ of random variables whose joint distribution can be written as
\begin{equation}
    \P_T(X_{0:T}\in dx_{0:T})=\P_0(dx_0)\prod\limits_{s=1}^T P_s(x_{s-1},x_s).
\end{equation}
The set $\mathcal{X}$ is the state-space, $\P_0$ is the initial distribution and the probability kernel $P_t$ is the transition kernel.
\end{definition}
It is possible to show that for any $t\in T,$
$$
\P_T(X_t\in dx_t\mid X_{0:t-1}\in dx_{0:t-1})=
\P_T(X_t\in dx_t\mid X_{t-1}=x_{t-1})=\P_t(x_{t-1},dx_t).
$$
The first equality implies conditional independence. The second equality implies that it is possible to identify conditional distributions with transition kernels. 
Assume $\P_t, t\leq T,$ is a sequence of probability measures. Then, the following proposition holds.
\begin{proposition}
For all $t\leq T,$ 
$$
\P_T(dx_{0:t})=\P_0(dx_0)\prod\limits_{s=1}^t P_s(x_{s-1},dx_s)=\P_t(dx_{0:t}).
$$
\end{proposition}
This means that the marginal distribution of $X_{0:t}$ with respect to $\P_T$ is $\P_t.$


\section{State-Space Models}


\chapter{Linear-Gaussian case}


\chapter{Particle Filtering}

\chapter{Applications to Stochastic Volatility Models}
\section{Comparing Constant and Stochastic Volatility Models of Equity Returns}

In this section, we apply the particle filter in a model-comparison
exercise, ultimately underlining the importance of taking stochastic
volatility into account in modeling equity returns.

We consider a stochastic volatility model
$$
\mathcal{M}_{SV}:\begin{array}{lc}
r_{t}=\alpha_{r}+\sigma_{r,t}\cdot v_{t}\\
\log\sigma_{r,t}^{2}=\alpha_{\sigma}+\beta_{\sigma}\cdot\log\sigma_{r,t-1}^{2}+\sigma_{\sigma}\cdot w_{t}
\end{array}\ (v_{t},w_{t})\sim\mathcal{N}_{2}(\boldsymbol{0},I_{2})
$$

and a constant volatility iid model 
$$
\mathcal{M}_{CV}:(r_{t})\overset{iid}{\sim}\mathcal{N}(\alpha,\sigma^{2}).
$$

We calibrate the model parameters using the whole sample, and proceed
by setting the return mean of both models to equal the sample mean,
$\sigma^{2}$ equal to the return variance, and the parameters of
the volatility equation in $\mathcal{M}_{SV}$ by running an $AR(1)$
regression of the log squared residuals.

In order to compare the predictive performance of the two, we compare
the cumulative log likelihood of the observed returns up to time $t$
given the considered model. In formulas, the cumulative likelihood
can be computed as
$$
p(y_{1:t}|\mathcal{M}_{i})=\prod_{s=0}^{t-1}p(y_{s+1}|y_{1:s},\mathcal{M}_{i}),i\in\{SV,CV\},
$$

adopting the convention $y_{1:0}=\emptyset$. This is trivial to obtain
in the iid case; considering the stohastic volatility model, the predictive
likelihoods can be derived as

$$
p(y_{t+1}|y_{1:t},\mathcal{M}_{SV})=\int p(y_{t+1}|\sigma_{r,t+1},y_{1:t},\mathcal{M}_{SV})p(\sigma_{r,t+1}|y_{1:t},\mathcal{M}_{SV})d(\sigma_{r,t+1})
$$
$$
=\int p(y_{t+1}|\sigma_{r,t+1}\mathcal{M}_{SV})p(\sigma_{r,t+1}|y_{1:t},\mathcal{M}_{SV})d(\sigma_{r,t+1})
$$

Whereas the emission distribution $p(y_{t+1}|\sigma_{r,t+1}\mathcal{M}_{SV})$
is known, we approximate the predictive state distribution $p(\sigma_{r,t+1}|y_{1:t},\mathcal{M}_{SV})$
with weighted particles obtained with particle filtering.

Figure XX reports the time series of the cumulative log-likelihood
given the constant volatility model $\mathcal{M}_{CV}$ relative to
the one given $\mathcal{M}_{SV}$, obtained as $\log p(y_{1:t}|\mathcal{M}_{CV})-\log p(y_{1:t}|\mathcal{M}_{SV})$.
Notice that the first difference of this series is the relative log-likelihood
of the incoming observation, $p(y_{t}|y_{1:t-1},\mathcal{M}_{CV})-p(y_{t}|y_{1:t-1},\mathcal{M}_{SV})$.

```{r cll_plot, echo=F, fig.align='center', fig.cap="Relative log-likelihood", fig.height=3, fig.pos='H', fig.width=10, results=F}
load("SV/cll_plot.Rda")
cll_plot+
  theme_bw()+
  scale_x_date(date_breaks = "3 months",date_minor_breaks="1 month",date_labels = "%m/%y")+
  labs(x="Time (month/year)",y="")
```
Overall, this analysis shows how a model with stochastic
volatility is better at describing and predicting returns. As can be seen from the graph and perhaps unsurprisingly,
the density forecast given the stochastic volatility model represents
a particularly significant improvement in the period of extreme values of returns in March 2020.
